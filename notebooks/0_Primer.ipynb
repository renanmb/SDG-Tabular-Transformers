{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "##\n",
    "## Copyright (C) 2022 NVIDIA Corporation.  All rights reserved.\n",
    "##\n",
    "## NVIDIA Sample Code\n",
    "##\n",
    "## Please refer to the NVIDIA end user license agreement (EULA) associated\n",
    "## with this source code for terms and conditions that govern your use of\n",
    "## this software. Any use, reproduction, disclosure, or distribution of\n",
    "## this software and related documentation outside the terms of the EULA\n",
    "## is strictly prohibited.\n",
    "##\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Synthetic Data Generation\n",
    "\n",
    "Synthetic Data Generation is a data augmentation technique and is necessary for increasing the robustness of models by supplying additional data to train models. \n",
    "\n",
    "An ideal <em>synthetic dataset</em> generated on top of real data is a dataset that shares with the real data:\n",
    "- the same features (columns)\n",
    "- for a particular feature, they share the same data type (integer, float, string, etc)\n",
    "- the same distributions in an individual column\n",
    "- the same joint distributions when considering multiple columns\n",
    "- the same conditional distributions (i.e. applying a condition on one distribution and looking at another)\n",
    "\n",
    "A <em>synthetic data generator</em> is a model that can be trained on the real data, and then be utilized to create new synthetic data with the properties described above.\n",
    "\n",
    "# Motivation and Financial Services Use Cases\n",
    "\n",
    "Synthetic data generation has some sample applications listed below:\n",
    "\n",
    "<strong>Fraud Detection</strong> - simulate payments data, insurance claims, or images\n",
    "\n",
    "<strong>Backtesting</strong> - simulate stock market data / order book data\n",
    "\n",
    "<strong>Loan Delinquency</strong> - simulate mortgage data\n",
    "\n",
    "<strong>Financial News or Forms</strong> - simulate financial news such as a macro event, or information on a 10-K \n",
    "\n",
    "\n",
    "The common themes in the sample applications above \n",
    "- Conditional Generation\n",
    "- Upsample infrequent data or edge cases\n",
    "- Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Methods\n",
    "\n",
    "Synthetic data generation methods can be segmented into classical and deep learning approaches. Classical approaches such as SMOTE may oversample certain data points, or generate new data points through interpolation of existing points. This can lead to issues where bias can be added to the model, or unrealistic or nonsensical data points can be generated, such as interpolating between zip codes or checking account numbers. Deep learning methods involve training a model, such as a Variational Autoencoder (VAE), which will encode the training data to a latent subspace followed by decoding the data back to the original feature space. Once trained, the user need only sample from the latent space and pass these samples through the decoder to produce synthetic output data. VAEs, GANs, and the like suffer from Posterior Collapse, where the synthetic data generator only outputs a single value, or Catastrophic forgetting where the model forgets previous information upon learning new information. In practice this makes a VAE or GAN model difficult for generating synthetic tabular data, especially if there are multiple high cardinality categorical features.\n",
    "\n",
    "### Classical:\n",
    "\n",
    "- Oversampling - ex. SMOTE (Synthetic minority oversampling)\n",
    "- Bagging - Bootstrap aggregation\n",
    "- Monte Carlo\n",
    "- PCA - Principal component analysis\n",
    "- Rotation, scaling, and cropping of images\n",
    "\n",
    "### Deep Learning:\n",
    "- (Variational) AutoEncoders\n",
    "- Generative Adversarial Networks (GANs)\n",
    "- RNNs, LSTMs, etc., and others.\n",
    "- Transformers (what we will focus on today)\n",
    "\n",
    "### Issues with Classical and earlier DL methods:\n",
    "- Loss of temporal information\n",
    "- Re-use existing datapoints, which can add bias to a model\n",
    "- Linear interpolation of existing datapoints, which may not be accurate or make sense for certain data (ex. categorical data such as zip codes)\n",
    "- Hard to create model that captures information on conditional distributions.\n",
    "- Catastrophic Forgetting - the model forgets previous information upon learning new information [[1]](#0_1)\n",
    "- Posterior collapse - the synthetic data generator only outputs a single value. [[2]](#0_2)\n",
    "\n",
    "\n",
    "### In this workshop, we will be exploring Transformers for synthetic tabular data generation. In our experience, using Transformers has yielded more accurate results in a shorter amount of time compared to the laborious and iterative process involved in training VAEs on large amounts of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Tabular data Synthetic Data Generation\n",
    "\n",
    "In addition to the points mentioned above for an ideal synthetic dataset, our synthetic tabular generator should:\n",
    "- Privacy-focused â€“ does not leak information about users in real data\n",
    "- Representative:\n",
    "    - Synthetic data accurately represents global trends, and local trends in the real data\n",
    "    - Relevant cross-column categorical features \n",
    "    - Maintain correlations for subsets of the data \n",
    "- Conditionally generated:\n",
    "    - Generate new data based on provided context\n",
    "    - Generate new edge case data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Credit Card Payments\n",
    "\n",
    "Throughout the rest of this workshop we will explore credit card payments using the TabFormer Dataset[[3]](#0_3), which itself was synthetically generated. An example of the credit card payments is shown below.\n",
    "\n",
    "| user | card | amount | date                | year | month | day  | hour | minute | use chip              | merchant name | merchant city | merchant state | zip   | mcc   | errors | is fraud |\n",
    "|------|------|------- |-------------------- |------|------ |------| -----| ------ | ----------------------| --------------| ------------- | -------------- | ----- | ---   | ------ | -------- |\n",
    "| 791  | 1    | 68.00  | 2018-01-02 09:10:00 | 2018 |  1    |  2   |  9   |     10 |    Swipe Transaction  | 12345536      |  New York     | NY             | 10017 |  8005 |  \\<NA> | 0        |\n",
    "| 1572 | 0    | 572.42 | 2018-04-12 07:11:00 | 2018 |  4    |  12  |  7   |     11 |    Chip Transaction   | 49908535      |  Princeton    | NJ             | 19406 |  5634 |  \\<NA> | 0        |\n",
    "| 2718 | 7    | 123.10 | 2019-01-04 10:14:00 | 2019 |  1    |  4   |  10  |     14 |    Chip Transaction   | 43211536      |  Beverly Hills| CA             | 90210 |  4800 |  \\<NA> | 0        |\n",
    "| 21   | 2    | 42.04  | 2020-06-23 11:18:00 | 2020 |  6    |  23  |  11  |     18 |    Swipe Transaction  | 65423006      |  Burke        | VA             | 22015 |  5604 |  \\<NA> | 0        |\n",
    "| 1001 | 1    | 5000.00| 2020-11-03 01:22:00 | 2020 |  11   |  3   |  1   |     22 |    Online Transaction | 75434546      |  \\<NA>        | \\<NA>          | \\<NA> |  1234 |  \\<NA> | 1        |\n",
    "\n",
    "\n",
    "A description of the columns is as follows:\n",
    "\n",
    "- <strong>user</strong> - (<em>integer</em>) the user id between 0-2000\n",
    "- <strong>card</strong>- (<em>integer</em>) the card id for a user between 0-8\n",
    "- <strong>amount</strong> - (<em>float</em>) the amount spent on a transaction from -500.00 (for a return) to ~10,000\n",
    "- <strong>year, month, day, hour, minute</strong> - (<em>integer</em>) the corresponding time a transaction occurred\n",
    "- <strong>use chip</strong> - (<em>string</em>) the transaction type, one of <em>Swipe Transaction, Chip Transaction, or Online Transaction</em>\n",
    "- <strong>merchant name</strong> - (<em>integer</em>) the merchant id, there are about 100,000 merchants total\n",
    "- <strong>merchant city, merchant state, zip</strong> - (<em>string) the city, state, and zip code where the transaction occurred. Will be NA if the transaction was online.\n",
    "- <strong>mcc</strong> - (<em>integer</em>) the <a href=\"https://www.investopedia.com/terms/m/merchant-category-codes-mcc.asp\">merchant category code</a> which is a 4-digit number categorizing the type of transaction. We will use this <a href=\"https://github.com/jleclanche/python-iso18245\">iso18245 repository</a> for looking up merchant category codes as needed.\n",
    "- <strong>errors</strong> - (<em>string</em>) a comma separated list of errors that occurred in the transaction.\n",
    "- <strong>is fraud</strong> - (<em>boolean</em>) whether the transaction is labeled fraudulent or not.\n",
    "\n",
    "\n",
    "\n",
    "#### A synthetic data generator for credit card transactions has some intricacies that make the modeling process particularly difficult.\n",
    "    \n",
    "#### At a high level, there are <strong>(1)</strong> different users, <strong>(2)</strong> in different geographic locations, <strong>(3)</strong> with different transaction profiles, and <strong>(4)</strong> have different payment methods/preferences, <strong>(5)</strong> features which are time dependent. Also, there is a mix of high cardinality categorical (zip codes, city, state), and continuous ( amount spent) columns, that must make sense. Ex. Beverly Hills, CA 90210 is the only acceptable combination of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "<a id=\"0_1\">[1]</a> \n",
    "<a href=\"https://www.researchgate.net/profile/Truyen-Tran-2/publication/326342681_On_catastrophic_forgetting_and_mode_collapse_in_Generative_Adversarial_Networks/links/5db7848992851c81801152e1/On-catastrophic-forgetting-and-mode-collapse-in-Generative-Adversarial-Networks.pdf\">Catastrophic forgetting and mode collapse in GANs</a></br>\n",
    "\n",
    "<a id=\"0_2\">[2]</a>\n",
    "<a href=\"https://openreview.net/pdf?id=r1xaVLUYuE\">Understanding Posterior Collapse in Generative Latent Variable Models</a></br>\n",
    "\n",
    "<a id=\"0_3\">[3]</a>\n",
    "<a href=\"https://github.com/IBM/TabFormer/tree/main\">Tabular Transformers for Modeling Multivariate Time Series</a></br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
